{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Retrieval with Metadata Filtering\n",
    "\n",
    "In this cookbook, we demonstrate how to enhance retrieval performance by implementing metadata filtering in your RAG applications. We'll explore how structured metadata can dramatically improve search relevance and precision beyond what vector similarity alone can achieve.\n",
    "\n",
    "When users search for products, documents, or other content, they often have specific attributes in mind. For example, a shopper might want \"red dresses for summer occasions\" or a researcher might need \"papers on climate change published after 2020.\" Pure semantic search might miss these nuances, but metadata filtering allows you to combine the power of vector search with explicit attribute filtering.\n",
    "\n",
    "Like always, we'll focus on data-driven approaches to measure and improve retrieval performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Before starting, ensure you have the following packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langwatch datasets pydantic openai instructor asyncio tenacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Start by setting up LangWatch to monitor your RAG application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import openai\n",
    "import getpass\n",
    "import langwatch\n",
    "\n",
    "# Display settings for better visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Initialize OpenAI, LangWatch & HuggingFace\n",
    "openai.api_key = getpass.getpass('Enter your OpenAI API key: ')\n",
    "langwatch.api_key = getpass.getpass('Enter your LangWatch API key: ')\n",
    "huggingface_api_key = getpass.getpass(\"Enter your Huggingface API key: \")\n",
    "chroma_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In this cookbook, we'll work with a product catalog dataset containing fashion items with structured metadata. The dataset includes:\n",
    "\n",
    "- **Basic product information**: titles, descriptions, brands, and prices\n",
    "- **Categorization**: categories, subcategories, and product types\n",
    "- **Attributes**: structured characteristics like sleeve length, neckline, and fit\n",
    "- **Materials and patterns**: fabric types and design patterns\n",
    "\n",
    "Here's what our taxonomy structure looks like:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"taxonomy_map\": {\n",
    "        \"Women\": {\n",
    "            \"Tops\": {\n",
    "                \"product_type\": [\"T-Shirts\", \"Blouses\", \"Sweaters\", \"Cardigans\", \"Tank Tops\", \"Hoodies\", \"Sweatshirts\"],\n",
    "                \"attributes\": {\n",
    "                    \"Sleeve Length\": [\"Sleeveless\", \"Short Sleeve\", \"3/4 Sleeve\", \"Long Sleeve\"],\n",
    "                    \"Neckline\": [\"Crew Neck\", \"V-Neck\", \"Turtleneck\", \"Scoop Neck\", \"Cowl Neck\"],\n",
    "                    \"Fit\": [\"Regular\", \"Slim\", \"Oversized\", \"Cropped\"]\n",
    "                }\n",
    "            },\n",
    "            \"Bottoms\": {\n",
    "                \"product_type\": [\"Pants\", \"Jeans\", \"Shorts\", \"Skirts\", \"Leggings\"],\n",
    "                \"attributes\": {\n",
    "                    // Additional attributes...\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Let's first load the dataset from Huggingface: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tahmidtapadar/Documents/cookbooks/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 191/191 [00:00<00:00, 4028.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "labelled_dataset = load_dataset(\"ivanleomk/labelled-ecommerce-taxonomy\")[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load it into our Chroma vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection with 191 documents.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# Initialize Chroma\n",
    "client = chromadb.PersistentClient()\n",
    "\n",
    "# Initialize embeddings\n",
    "embedding_function = OpenAIEmbeddingFunction(model_name=\"text-embedding-3-large\", api_key=openai.api_key)\n",
    "\n",
    "# Create collections\n",
    "collection = client.get_or_create_collection(name=\"collection\", embedding_function=embedding_function)\n",
    "\n",
    "# Add documents to both collections\n",
    "for row in labelled_dataset:\n",
    "    collection.add(\n",
    "        documents=[row['description']],\n",
    "        ids=[str(row['id'])],\n",
    "        metadatas = {\n",
    "            'category': row['category'],\n",
    "            'subcategory': row['subcategory'],\n",
    "            'product_type': row['product_type'],\n",
    "            'occasions': row['occasions'],\n",
    "            'brand': row['brand'],\n",
    "            'price': float(row['price']),\n",
    "            'attributes': row['attributes'],\n",
    "            'material': row['material'],\n",
    "            'pattern': row['pattern'],\n",
    "            'title': row['title'],\n",
    "            'id': row['id']\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Created collection with {collection.count()} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data\n",
    "\n",
    "When you don't have production data to start with, you can generate synthetic data to simulate a real-world scenario. We already have the 'output', which is the clothing item we just embedded. We now want to generate synthetic queries that would be relevant to the clothing item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating queries: 100%|██████████| 191/191 [02:56<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key)  \n",
    "\n",
    "# Define query types to generate variety\n",
    "query_types = [\n",
    "    \"Basic search for specific item\",\n",
    "    \"Search with price constraint\",\n",
    "    \"Search for specific occasion\",\n",
    "    \"Search with material preference\",\n",
    "    \"Search with style/attribute preference\"\n",
    "]\n",
    "\n",
    "def generate_synthetic_query(item):\n",
    "    \"\"\"Generate a realistic search query for a clothing item\"\"\"\n",
    "    \n",
    "    # Select a random query type\n",
    "    query_type = random.choice(query_types)\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Generate a realistic search query that would lead someone to find this specific clothing item:\n",
    "    \n",
    "    Item Details:\n",
    "    - Title: {item[\"title\"]}\n",
    "    - Description: {item[\"description\"]}\n",
    "    - Category: {item[\"category\"]}\n",
    "    - Subcategory: {item[\"subcategory\"]}\n",
    "    - Product Type: {item[\"product_type\"]}\n",
    "    - Price: ${item[\"price\"]}\n",
    "    - Material: {item[\"material\"]}\n",
    "    - Attributes: {item[\"attributes\"]}\n",
    "    - Occasions: {item[\"occasions\"]}\n",
    "    \n",
    "    The query should be in a conversational tone, about 10-20 words, and focus on a {query_type.lower()}.\n",
    "    Don't mention the exact product name, but include specific details that would make this item a perfect match.\n",
    "    \n",
    "    Example: For a $120 silk blouse with long sleeves, a query might be:\n",
    "    \"Looking for an elegant silk top with long sleeves for work, under $150\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate query using OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates realistic shopping queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the generated query\n",
    "    query = response.choices[0].message.content.strip().strip('\"')\n",
    "    \n",
    "    return {\"query\": query, **item}\n",
    "\n",
    "# Generate queries\n",
    "synthetic_queries = []\n",
    "for item in tqdm(labelled_dataset, desc=\"Generating queries\"):\n",
    "    query_data = generate_synthetic_query(item)\n",
    "    synthetic_queries.append(query_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what this looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Searching for a sleeveless top with lace detailing at the neckline for casual outings and dinner </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dates.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PIL.JpegImagePlugin.JpegImageFile</span><span style=\"color: #000000; text-decoration-color: #000000\"> image </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">RGB</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #808000; text-decoration-color: #808000\">size</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">768x1024</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13E0BB230</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lace Detail Sleeveless Top'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brand'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'H&amp;M'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comfort.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'subcategory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'product_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tank Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'material'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pattern'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solid'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181.04</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'occasions'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"]'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m'Searching for a sleeveless top with lace detailing at the neckline for casual outings and dinner \u001b[0m\n",
       "\u001b[32mdates.'\u001b[0m,\n",
       "    \u001b[32m'image'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mPIL.JpegImagePlugin.JpegImageFile\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mRGB\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m768x1024\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x13E0BB230\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Lace Detail Sleeveless Top'\u001b[0m,\n",
       "    \u001b[32m'brand'\u001b[0m: \u001b[32m'H&M'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace \u001b[0m\n",
       "\u001b[32mdetailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day \u001b[0m\n",
       "\u001b[32mcomfort.\"\u001b[0m,\n",
       "    \u001b[32m'category'\u001b[0m: \u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[32m'subcategory'\u001b[0m: \u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[32m'product_type'\u001b[0m: \u001b[32m'Tank Tops'\u001b[0m,\n",
       "    \u001b[32m'attributes'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Neckline\", \"value\": \"Crew Neck\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'material'\u001b[0m: \u001b[32m'Cotton'\u001b[0m,\n",
       "    \u001b[32m'pattern'\u001b[0m: \u001b[32m'Solid'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'price'\u001b[0m: \u001b[1;36m181.04\u001b[0m,\n",
       "    \u001b[32m'occasions'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "print(synthetic_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Filtering\n",
    "\n",
    "Semantic search often misses specific requirements in complex queries like \"silk blouse, long sleeves, under $100, for office wear.\" It may return cotton blouses, short sleeves, items over $100, or casual styles - all technically relevant but failing to meet explicit criteria.\n",
    "\n",
    "We'll now extract filters from natural language queries and map them to our taxonomy. This allows us to:\n",
    "1. Find semantically relevant items\n",
    "2. Filter out those that don't meet specific requirements\n",
    "\n",
    "We'll implement this using Pydantic models to validate extracted filters against our available metadata structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Attribute(BaseModel):\n",
    "    name: str\n",
    "    values: list[str]\n",
    "\n",
    "class QueryFilters(BaseModel):\n",
    "    attributes: list[Attribute]\n",
    "    material: Optional[list[str]]\n",
    "    min_price: Optional[float] = None\n",
    "    max_price: Optional[float] = None\n",
    "    subcategory: str\n",
    "    category: str\n",
    "    product_type: list[str]\n",
    "    occasions: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these models in place, we can start extracting query filters from all queries. We need to let the LLM know what the possible taxonomies are. We'll use the taxonomy.json file for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting filters:   0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting filters: 100%|██████████| 191/191 [10:56<00:00,  3.44s/it] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load taxonomy\n",
    "taxonomy = json.load(open(\"../data/taxonomy.json\"))\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key)  \n",
    "\n",
    "def extract_filters(item):\n",
    "    \"\"\"Extract filters from item metadata\"\"\"\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Extract shopping filters from this query: \"{item['query']}\"\n",
    "    \n",
    "    Return ONLY a JSON object with these possible keys:\n",
    "    - category: The clothing category (e.g., \"Women\")\n",
    "    - subcategory: The subcategory (e.g., \"Tops\", \"Bottoms\")\n",
    "    - product_type: The specific product type (e.g., \"T-Shirts\", \"Jeans\")\n",
    "    - max_price: Maximum price as a number (no $ symbol)\n",
    "    - min_price: Minimum price as a number (no $ symbol)\n",
    "    - material: The material (e.g., \"Cotton\", \"Polyester\")\n",
    "    - occasion: The occasion (e.g., \"Casual\", \"Formal\")\n",
    "    \n",
    "    Only include keys that are explicitly mentioned in the query.\n",
    "    Use ONLY values from the taxonomy I'll provide\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get completion from OpenAI\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured shopping filters from text queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Taxonomy data: {taxonomy}\"}\n",
    "        ],\n",
    "        text_format=QueryFilters\n",
    "    )\n",
    "    \n",
    "    # Extract the generated query\n",
    "    filters = response.output_parsed\n",
    "    \n",
    "    return filters\n",
    "\n",
    "# Extract Filters\n",
    "filters = []\n",
    "for item in tqdm(synthetic_queries, desc=\"Extracting filters\"):\n",
    "    filters.append(extract_filters(item))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation: Semantic Search vs. Metadata Filtering\n",
    "\n",
    "With all the building blocks in place, we can now evaluate our retrieval system's performance. Following the methodology from our previous cookbooks, we'll measure effectiveness using two key metrics:\n",
    "\n",
    "1. **Recall**: The proportion of relevant items successfully retrieved\n",
    "2. **Mean Reciprocal Rank (MRR)**: How high relevant items appear in our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(predictions: list[str], ground_truth: list[str]):\n",
    "    \"\"\"Calculate the proportion of relevant items that were retrieved\"\"\"\n",
    "    return len([label for label in ground_truth if label in predictions]) / len(ground_truth)\n",
    "\n",
    "def calculate_mrr(predictions: list[str], ground_truth: list[str]):\n",
    "    \"\"\"Calculate Mean Reciprocal Rank - how high the relevant items appear in results\"\"\"\n",
    "    mrr = 0\n",
    "    for label in ground_truth:\n",
    "        if label in predictions:\n",
    "            # Find the position of the first relevant item\n",
    "            mrr = max(mrr, 1 / (predictions.index(label) + 1))\n",
    "    return mrr\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_retrieval(retrieved_ids, expected_ids):\n",
    "    \"\"\"Evaluate retrieval performance using recall and MRR\"\"\"\n",
    "    recall = calculate_recall(retrieved_ids, expected_ids)\n",
    "    mrr = calculate_mrr(retrieved_ids, expected_ids)\n",
    "    \n",
    "    return {\"recall\": recall, \"mrr\": mrr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this evaluation, we'll compare two distinct retrieval approaches:\n",
    "\n",
    "- **Pure Semantic Search**: Using only vector embeddings to find similar items\n",
    "- **Semantic Search with Metadata Filtering**: Combining vector similarity with structured metadata filters\n",
    "\n",
    "This comparison will demonstrate how metadata filtering can significantly improve retrieval precision and relevance, especially for queries with specific attributes or constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function for pure semantic search\n",
    "def pure_semantic_search(query, collection, k=5):\n",
    "    \"\"\"Perform pure semantic search without metadata filtering\"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=k\n",
    "    )\n",
    "    \n",
    "    retrieved_ids = results['ids'][0]\n",
    "    \n",
    "    return retrieved_ids\n",
    "\n",
    "# Define a function for semantic search with metadata filtering\n",
    "def semantic_search_with_metadata(query, collection, filters, k=5):\n",
    "    \"\"\"Perform semantic search with metadata filtering\"\"\"\n",
    "    # Initialize empty where conditions list\n",
    "    where_conditions = []\n",
    "    \n",
    "    # Only proceed if we have filters\n",
    "    if filters:\n",
    "        # Add category filter if it exists\n",
    "        if hasattr(filters, 'category') and filters.category:\n",
    "            where_conditions.append({\"category\": filters.category})\n",
    "        \n",
    "        # Add product_type filter if it exists\n",
    "        if hasattr(filters, 'product_type') and filters.product_type:\n",
    "            if isinstance(filters.product_type, list):\n",
    "                where_conditions.append({\"product_type\": {\"$in\": filters.product_type}})\n",
    "            else:\n",
    "                where_conditions.append({\"product_type\": filters.product_type})\n",
    "        \n",
    "        # Add material filter if it exists\n",
    "        if hasattr(filters, 'material') and filters.material:\n",
    "            where_conditions.append({\"material\": filters.material})\n",
    "        \n",
    "        # Add occasion filter if it exists\n",
    "        if hasattr(filters, 'occasion') and filters.occasion:\n",
    "            if isinstance(filters.occasion, list):\n",
    "                where_conditions.append({\"occasions\": {\"$in\": filters.occasion}})\n",
    "            else:\n",
    "                where_conditions.append({\"occasions\": filters.occasion})\n",
    "        \n",
    "        # Add price range filters if they exist\n",
    "        if hasattr(filters, 'min_price') and filters.min_price is not None:\n",
    "            where_conditions.append({\"price\": {\"$gte\": filters.min_price}})\n",
    "            \n",
    "        if hasattr(filters, 'max_price') and filters.max_price is not None:\n",
    "            where_conditions.append({\"price\": {\"$lte\": filters.max_price}})\n",
    "        \n",
    "        # Add attributes if they exist\n",
    "        if hasattr(filters, 'attributes') and filters.attributes:\n",
    "            # Check if attributes is a string (JSON) and parse it\n",
    "            if isinstance(filters.attributes, str):\n",
    "                try:\n",
    "                    import json\n",
    "                    attributes_list = json.loads(filters.attributes)\n",
    "                except:\n",
    "                    attributes_list = []\n",
    "            else:\n",
    "                attributes_list = filters.attributes\n",
    "                \n",
    "            # Process attributes as a list of dictionaries with name/value pairs\n",
    "            if isinstance(attributes_list, list):\n",
    "                for attr in attributes_list:\n",
    "                    if isinstance(attr, dict) and 'name' in attr and 'value' in attr:\n",
    "                        attr_name = attr['name']\n",
    "                        attr_value = attr['value']\n",
    "                        \n",
    "                        # Add to where conditions\n",
    "                        where_conditions.append({f\"attributes.{attr_name}\": attr_value})\n",
    "    \n",
    "    # Construct the final where clause\n",
    "    where_clause = None\n",
    "    if where_conditions:\n",
    "        if len(where_conditions) == 1:\n",
    "            # If only one condition, use it directly\n",
    "            where_clause = where_conditions[0]\n",
    "        else:\n",
    "            # If multiple conditions, use $and operator\n",
    "            where_clause = {\"$and\": where_conditions}\n",
    "    \n",
    "    # Perform the query with or without where filtering\n",
    "    try:\n",
    "        if where_clause:\n",
    "            results = collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=k,\n",
    "                where=where_clause\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to pure semantic search if no filters were extracted\n",
    "            results = collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=k\n",
    "            )\n",
    "        \n",
    "        retrieved_ids = results['ids'][0]\n",
    "        \n",
    "        return retrieved_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error in semantic_search_with_metadata: {e}\")\n",
    "        # Fallback to pure semantic search\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=k\n",
    "        )\n",
    "        return results['ids'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to run the evaluation\n",
    "def run_evaluation(queries, expected_ids, collection, k_values=[3, 5, 10]):\n",
    "    \"\"\"Run evaluation for both retrieval methods across different k values\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for k in tqdm(k_values, desc=\"Evaluating k values\"):\n",
    "        pure_semantic_metrics = []\n",
    "        metadata_filtering_metrics = []\n",
    "        \n",
    "        for i, (query, expected) in enumerate(tqdm(zip(queries, expected_ids), desc=f\"Evaluating queries for k={k}\", total=len(queries))):\n",
    "            # Get the filters for this query\n",
    "            query_filters = filters[i] if i < len(filters) else None\n",
    "            \n",
    "            # Run pure semantic search\n",
    "            pure_semantic_results = pure_semantic_search(query, collection, k=k)\n",
    "            pure_semantic_eval = evaluate_retrieval(pure_semantic_results, expected)\n",
    "            pure_semantic_metrics.append(pure_semantic_eval)\n",
    "            \n",
    "            # Run semantic search with metadata filtering\n",
    "            metadata_results = semantic_search_with_metadata(query, collection, query_filters, k=k)\n",
    "            metadata_eval = evaluate_retrieval(metadata_results, expected)\n",
    "            metadata_filtering_metrics.append(metadata_eval)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_pure_recall = np.mean([m[\"recall\"] for m in pure_semantic_metrics])\n",
    "        avg_pure_mrr = np.mean([m[\"mrr\"] for m in pure_semantic_metrics])\n",
    "        \n",
    "        avg_metadata_recall = np.mean([m[\"recall\"] for m in metadata_filtering_metrics])\n",
    "        avg_metadata_mrr = np.mean([m[\"mrr\"] for m in metadata_filtering_metrics])\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": \"pure_semantic\",\n",
    "            \"avg_recall\": avg_pure_recall,\n",
    "            \"avg_mrr\": avg_pure_mrr\n",
    "        })\n",
    "        \n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": \"metadata_filtering\",\n",
    "            \"avg_recall\": avg_metadata_recall,\n",
    "            \"avg_mrr\": avg_metadata_mrr\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k values:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Cotton'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Cotton'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Cotton'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Cotton'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Denim'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Denim'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span><span style=\"font-weight: bold\">]</span> in query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error in semantic_search_with_metadata: Expected where value to be a str, int, float, or operator expression, got \n",
       "\u001b[1m[\u001b[0m\u001b[32m'Cotton'\u001b[0m\u001b[1m]\u001b[0m in query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries for k=3:   8%|▊         | 15/191 [00:19<03:54,  1.33s/it]\n",
      "Evaluating k values:   0%|          | 0/4 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[32m      6\u001b[39m k_values = [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m20\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results_df = \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mrun_evaluation\u001b[39m\u001b[34m(queries, expected_ids, collection, k_values)\u001b[39m\n\u001b[32m    127\u001b[39m pure_semantic_metrics.append(pure_semantic_eval)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Run semantic search with metadata filtering\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m metadata_results = \u001b[43msemantic_search_with_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m metadata_eval = evaluate_retrieval(metadata_results, expected)\n\u001b[32m    132\u001b[39m metadata_filtering_metrics.append(metadata_eval)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36msemantic_search_with_metadata\u001b[39m\u001b[34m(query, collection, filters, k)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m where_clause:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         results = \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere_clause\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m# Fallback to pure semantic search if no filters were extracted\u001b[39;00m\n\u001b[32m     94\u001b[39m         results = collection.query(\n\u001b[32m     95\u001b[39m             query_texts=[query],\n\u001b[32m     96\u001b[39m             n_results=k\n\u001b[32m     97\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py:208\u001b[39m, in \u001b[36mCollection.query\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    167\u001b[39m     query_embeddings: Optional[\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m     ],\n\u001b[32m    184\u001b[39m ) -> QueryResult:\n\u001b[32m    185\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m    187\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \n\u001b[32m    206\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     query_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_query_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     query_results = \u001b[38;5;28mself\u001b[39m._client._query(\n\u001b[32m    220\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    221\u001b[39m         query_embeddings=query_request[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    228\u001b[39m     )\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_query_response(\n\u001b[32m    231\u001b[39m         response=query_results, include=query_request[\u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    232\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:321\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_query_request\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m query_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    320\u001b[39m     validate_record_set_for_embedding(record_set=query_records)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     request_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     request_embeddings = query_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:555\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    551\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    552\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    553\u001b[39m             )\n\u001b[32m    554\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:568\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    564\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    565\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    566\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    567\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/api/types.py:491\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/openai_embedding_function.py:119\u001b[39m, in \u001b[36mOpenAIEmbeddingFunction.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    116\u001b[39m     embedding_params[\u001b[33m\"\u001b[39m\u001b[33mdimensions\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.dimensions\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43membedding_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Extract embeddings from response\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [np.array(data.embedding, dtype=np.float32) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m response.data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/openai/resources/embeddings.py:128\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    122\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    123\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m             ).tolist()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/openai/_base_client.py:1247\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1235\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1242\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1243\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1244\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1245\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1246\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/openai/_base_client.py:920\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/openai/_base_client.py:960\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m    957\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, request.method, request.url)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    966\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpx/_client.py:926\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    924\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpx/_client.py:954\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    951\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    960\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpx/_client.py:991\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    989\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpx/_client.py:1027\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m     )\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1031\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpx/_transports/default.py:236\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    223\u001b[39m req = httpcore.Request(\n\u001b[32m    224\u001b[39m     method=request.method,\n\u001b[32m    225\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     extensions=request.extensions,\n\u001b[32m    234\u001b[39m )\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    241\u001b[39m     status_code=resp.status,\n\u001b[32m    242\u001b[39m     headers=resp.headers,\n\u001b[32m    243\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    244\u001b[39m     extensions=resp.extensions,\n\u001b[32m    245\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cookbooks/venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Prepare the evaluation data\n",
    "queries = [item[\"query\"] for item in synthetic_queries]\n",
    "expected_ids = [[item[\"id\"]] for item in synthetic_queries]  # Each expected ID as a list\n",
    "\n",
    "# Run the evaluation\n",
    "k_values = [3, 5, 10, 20]\n",
    "results_df = run_evaluation(queries, expected_ids, collection, k_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
