{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Retrieval with Metadata Filtering\n",
    "\n",
    "In this cookbook, we demonstrate how to enhance retrieval performance by implementing metadata filtering in your RAG applications. We'll explore how structured metadata can dramatically improve search relevance and precision beyond what vector similarity alone can achieve.\n",
    "\n",
    "When users search for products, documents, or other content, they often have specific attributes in mind. For example, a shopper might want \"red dresses for summer occasions\" or a researcher might need \"papers on climate change published after 2020.\" Pure semantic search might miss these nuances, but metadata filtering allows you to combine the power of vector search with explicit attribute filtering.\n",
    "\n",
    "Like always, we'll focus on data-driven approaches to measure and improve retrieval performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Before starting, ensure you have the following packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langwatch datasets pydantic openai instructor asyncio tenacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Start by setting up LangWatch to monitor your RAG application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import openai\n",
    "import getpass\n",
    "import langwatch\n",
    "\n",
    "# Display settings for better visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Initialize OpenAI, LangWatch & HuggingFace\n",
    "openai.api_key = getpass.getpass('Enter your OpenAI API key: ')\n",
    "langwatch.api_key = getpass.getpass('Enter your LangWatch API key: ')\n",
    "huggingface_api_key = getpass.getpass(\"Enter your Huggingface API key: \")\n",
    "chroma_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In this cookbook, we'll work with a product catalog dataset containing fashion items with structured metadata. The dataset includes:\n",
    "\n",
    "- **Basic product information**: titles, descriptions, brands, and prices\n",
    "- **Categorization**: categories, subcategories, and product types\n",
    "- **Attributes**: structured characteristics like sleeve length, neckline, and fit\n",
    "- **Materials and patterns**: fabric types and design patterns\n",
    "\n",
    "Here's what our taxonomy structure looks like:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"taxonomy_map\": {\n",
    "        \"Women\": {\n",
    "            \"Tops\": {\n",
    "                \"product_type\": [\"T-Shirts\", \"Blouses\", \"Sweaters\", \"Cardigans\", \"Tank Tops\", \"Hoodies\", \"Sweatshirts\"],\n",
    "                \"attributes\": {\n",
    "                    \"Sleeve Length\": [\"Sleeveless\", \"Short Sleeve\", \"3/4 Sleeve\", \"Long Sleeve\"],\n",
    "                    \"Neckline\": [\"Crew Neck\", \"V-Neck\", \"Turtleneck\", \"Scoop Neck\", \"Cowl Neck\"],\n",
    "                    \"Fit\": [\"Regular\", \"Slim\", \"Oversized\", \"Cropped\"]\n",
    "                }\n",
    "            },\n",
    "            \"Bottoms\": {\n",
    "                \"product_type\": [\"Pants\", \"Jeans\", \"Shorts\", \"Skirts\", \"Leggings\"],\n",
    "                \"attributes\": {\n",
    "                    // Additional attributes...\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Let's first load the dataset from Huggingface: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tahmidtapadar/Documents/cookbooks/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 191/191 [00:00<00:00, 4028.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "labelled_dataset = load_dataset(\"ivanleomk/labelled-ecommerce-taxonomy\")[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load it into our Chroma vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection with 191 documents.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# Initialize Chroma\n",
    "client = chromadb.PersistentClient()\n",
    "\n",
    "# Initialize embeddings\n",
    "embedding_function = OpenAIEmbeddingFunction(model_name=\"text-embedding-3-large\", api_key=openai.api_key)\n",
    "\n",
    "# Create collections\n",
    "collection = client.get_or_create_collection(name=\"collection\", embedding_function=embedding_function)\n",
    "\n",
    "# Add documents to both collections\n",
    "for row in labelled_dataset:\n",
    "    collection.add(\n",
    "        documents=[row['description']],\n",
    "        ids=[str(row['id'])],\n",
    "        metadatas = {\n",
    "            'category': row['category'],\n",
    "            'subcategory': row['subcategory'],\n",
    "            'product_type': row['product_type'],\n",
    "            'occasions': row['occasions'],\n",
    "            'brand': row['brand'],\n",
    "            'price': float(row['price']),\n",
    "            'attributes': row['attributes'],\n",
    "            'material': row['material'],\n",
    "            'pattern': row['pattern'],\n",
    "            'title': row['title'],\n",
    "            'id': row['id']\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Created collection with {collection.count()} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data\n",
    "\n",
    "When you don't have production data to start with, you can generate synthetic data to simulate a real-world scenario. We already have the 'output', which is the clothing item we just embedded. We now want to generate synthetic queries that would be relevant to the clothing item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating queries: 100%|██████████| 191/191 [02:56<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key)  \n",
    "\n",
    "# Define query types to generate variety\n",
    "query_types = [\n",
    "    \"Basic search for specific item\",\n",
    "    \"Search with price constraint\",\n",
    "    \"Search for specific occasion\",\n",
    "    \"Search with material preference\",\n",
    "    \"Search with style/attribute preference\"\n",
    "]\n",
    "\n",
    "def generate_synthetic_query(item):\n",
    "    \"\"\"Generate a realistic search query for a clothing item\"\"\"\n",
    "    \n",
    "    # Select a random query type\n",
    "    query_type = random.choice(query_types)\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Generate a realistic search query that would lead someone to find this specific clothing item:\n",
    "    \n",
    "    Item Details:\n",
    "    - Title: {item[\"title\"]}\n",
    "    - Description: {item[\"description\"]}\n",
    "    - Category: {item[\"category\"]}\n",
    "    - Subcategory: {item[\"subcategory\"]}\n",
    "    - Product Type: {item[\"product_type\"]}\n",
    "    - Price: ${item[\"price\"]}\n",
    "    - Material: {item[\"material\"]}\n",
    "    - Attributes: {item[\"attributes\"]}\n",
    "    - Occasions: {item[\"occasions\"]}\n",
    "    \n",
    "    The query should be in a conversational tone, about 10-20 words, and focus on a {query_type.lower()}.\n",
    "    Don't mention the exact product name, but include specific details that would make this item a perfect match.\n",
    "    \n",
    "    Example: For a $120 silk blouse with long sleeves, a query might be:\n",
    "    \"Looking for an elegant silk top with long sleeves for work, under $150\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate query using OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates realistic shopping queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the generated query\n",
    "    query = response.choices[0].message.content.strip().strip('\"')\n",
    "    \n",
    "    return {\"query\": query, **item}\n",
    "\n",
    "# Generate queries\n",
    "synthetic_queries = []\n",
    "for item in tqdm(labelled_dataset, desc=\"Generating queries\"):\n",
    "    query_data = generate_synthetic_query(item)\n",
    "    synthetic_queries.append(query_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what this looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Searching for a sleeveless top with lace detailing at the neckline for casual outings and dinner </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dates.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PIL.JpegImagePlugin.JpegImageFile</span><span style=\"color: #000000; text-decoration-color: #000000\"> image </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">RGB</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #808000; text-decoration-color: #808000\">size</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080\">768x1024</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13E0BB230</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lace Detail Sleeveless Top'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brand'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'H&amp;M'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comfort.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Women'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'subcategory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'product_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tank Tops'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[{\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"}, {\"name\": \"Neckline\", \"value\": \"Crew Neck\"}]'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'material'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Cotton'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pattern'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solid'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181.04</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'occasions'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"]'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m'Searching for a sleeveless top with lace detailing at the neckline for casual outings and dinner \u001b[0m\n",
       "\u001b[32mdates.'\u001b[0m,\n",
       "    \u001b[32m'image'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mPIL.JpegImagePlugin.JpegImageFile\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mRGB\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m768x1024\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x13E0BB230\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Lace Detail Sleeveless Top'\u001b[0m,\n",
       "    \u001b[32m'brand'\u001b[0m: \u001b[32m'H&M'\u001b[0m,\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m\"Elevate your casual wardrobe with this elegant sleeveless top featuring intricate lace \u001b[0m\n",
       "\u001b[32mdetailing at the neckline. Perfect for both day and night, it's crafted from a soft, breathable fabric for all-day \u001b[0m\n",
       "\u001b[32mcomfort.\"\u001b[0m,\n",
       "    \u001b[32m'category'\u001b[0m: \u001b[32m'Women'\u001b[0m,\n",
       "    \u001b[32m'subcategory'\u001b[0m: \u001b[32m'Tops'\u001b[0m,\n",
       "    \u001b[32m'product_type'\u001b[0m: \u001b[32m'Tank Tops'\u001b[0m,\n",
       "    \u001b[32m'attributes'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Sleeve Length\", \"value\": \"Sleeveless\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"name\": \"Neckline\", \"value\": \"Crew Neck\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'material'\u001b[0m: \u001b[32m'Cotton'\u001b[0m,\n",
       "    \u001b[32m'pattern'\u001b[0m: \u001b[32m'Solid'\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'price'\u001b[0m: \u001b[1;36m181.04\u001b[0m,\n",
       "    \u001b[32m'occasions'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Everyday Wear\", \"Casual Outings\", \"Smart Casual\", \"Dinner Dates\", \"Partywear\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "print(synthetic_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Filtering\n",
    "\n",
    "Semantic search often misses specific requirements in complex queries like \"silk blouse, long sleeves, under $100, for office wear.\" It may return cotton blouses, short sleeves, items over $100, or casual styles - all technically relevant but failing to meet explicit criteria.\n",
    "\n",
    "We'll now extract filters from natural language queries and map them to our taxonomy. This allows us to:\n",
    "1. Find semantically relevant items\n",
    "2. Filter out those that don't meet specific requirements\n",
    "\n",
    "We'll implement this using Pydantic models to validate extracted filters against our available metadata structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Attribute(BaseModel):\n",
    "    name: str\n",
    "    values: list[str]\n",
    "\n",
    "class QueryFilters(BaseModel):\n",
    "    attributes: list[Attribute]\n",
    "    material: Optional[list[str]]\n",
    "    min_price: Optional[float] = None\n",
    "    max_price: Optional[float] = None\n",
    "    subcategory: str\n",
    "    category: str\n",
    "    product_type: list[str]\n",
    "    occasions: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these models in place, we can start extracting query filters from all queries. We need to let the LLM know what the possible taxonomies are. We'll use the taxonomy.json file for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting filters: 100%|██████████| 191/191 [07:42<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load taxonomy\n",
    "taxonomy = json.load(open(\"../data/taxonomy.json\"))\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key)  \n",
    "\n",
    "def extract_filters(item):\n",
    "    \"\"\"Extract filters from item metadata\"\"\"\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Extract shopping filters from this query: \"{item['query']}\"\n",
    "    \n",
    "    Return ONLY a JSON object with these possible keys:\n",
    "    - category: The clothing category (e.g., \"Women\")\n",
    "    - subcategory: The subcategory (e.g., \"Tops\", \"Bottoms\")\n",
    "    - product_type: The specific product type (e.g., \"T-Shirts\", \"Jeans\")\n",
    "    - max_price: Maximum price as a number (no $ symbol)\n",
    "    - min_price: Minimum price as a number (no $ symbol)\n",
    "    - material: The material (e.g., \"Cotton\", \"Polyester\")\n",
    "    - occasion: The occasion (e.g., \"Casual\", \"Formal\")\n",
    "    \n",
    "    Only include keys that are explicitly mentioned in the query.\n",
    "    Use ONLY values from the taxonomy I'll provide\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get completion from OpenAI\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured shopping filters from text queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Taxonomy data: {taxonomy}\"}\n",
    "        ],\n",
    "        text_format=QueryFilters\n",
    "    )\n",
    "    \n",
    "    # Extract the generated query\n",
    "    filters = response.output_parsed\n",
    "    \n",
    "    return filters\n",
    "\n",
    "# Extract Filters\n",
    "filters = []\n",
    "for item in tqdm(synthetic_queries, desc=\"Extracting filters\"):\n",
    "    filters.append(extract_filters(item))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation: Semantic Search vs. Metadata Filtering\n",
    "\n",
    "With all the building blocks in place, we can now evaluate our retrieval system's performance. Following the methodology from our previous cookbooks, we'll measure effectiveness using two key metrics:\n",
    "\n",
    "1. **Recall**: The proportion of relevant items successfully retrieved\n",
    "2. **Mean Reciprocal Rank (MRR)**: How high relevant items appear in our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(predictions: list[str], ground_truth: list[str]):\n",
    "    \"\"\"Calculate the proportion of relevant items that were retrieved\"\"\"\n",
    "    return len([label for label in ground_truth if label in predictions]) / len(ground_truth)\n",
    "\n",
    "def calculate_mrr(predictions: list[str], ground_truth: list[str]):\n",
    "    \"\"\"Calculate Mean Reciprocal Rank - how high the relevant items appear in results\"\"\"\n",
    "    mrr = 0\n",
    "    for label in ground_truth:\n",
    "        if label in predictions:\n",
    "            # Find the position of the first relevant item\n",
    "            mrr = max(mrr, 1 / (predictions.index(label) + 1))\n",
    "    return mrr\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_retrieval(retrieved_ids, expected_ids):\n",
    "\n",
    "    \"\"\"Evaluate retrieval performance using recall and MRR\"\"\"\n",
    "    recall = calculate_recall(retrieved_ids, expected_ids)\n",
    "    mrr = calculate_mrr(retrieved_ids, expected_ids)\n",
    "    \n",
    "    return {\"recall\": recall, \"mrr\": mrr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this evaluation, we'll compare two distinct retrieval approaches:\n",
    "\n",
    "- **Pure Semantic Search**: Using only vector embeddings to find similar items\n",
    "- **Semantic Search with Metadata Filtering**: Combining vector similarity with structured metadata filters\n",
    "\n",
    "This comparison will demonstrate how metadata filtering can significantly improve retrieval precision and relevance, especially for queries with specific attributes or constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function for pure semantic search\n",
    "def pure_semantic_search(query, collection, k=5):\n",
    "    \"\"\"Perform pure semantic search without metadata filtering\"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=k\n",
    "    )\n",
    "    \n",
    "    retrieved_ids = results['ids'][0]\n",
    "    \n",
    "    return retrieved_ids\n",
    "\n",
    "# Define a function for semantic search with metadata filtering\n",
    "def semantic_search_with_metadata(query, collection, filters, k=5):\n",
    "    \"\"\"Perform semantic search with metadata filtering\"\"\"\n",
    "    # Only proceed with filtering if filters are provided\n",
    "    where_clause = None\n",
    "    \n",
    "    if filters:\n",
    "        where_conditions = []\n",
    "        \n",
    "        # Add filters for each attribute\n",
    "        where_conditions.append({\"category\": filters.category}) if filters.category else None\n",
    "        where_conditions.append({\"subcategory\": filters.subcategory}) if filters.subcategory else None\n",
    "        where_conditions.append({\"product_type\": {\"$in\": filters.product_type}}) if filters.product_type else None\n",
    "        where_conditions.append({\"material\": {\"$in\": filters.material}}) if filters.material else None\n",
    "        where_conditions.append({\"price\": {\"$gte\": filters.min_price}}) if filters.min_price else None\n",
    "        where_conditions.append({\"price\": {\"$lte\": filters.max_price}}) if filters.max_price else None\n",
    "        \n",
    "        # Combine all conditions with $and operator if we have multiple conditions\n",
    "        if len(where_conditions) > 1:\n",
    "            where_clause = {\n",
    "                \"$and\": where_conditions\n",
    "            }\n",
    "        elif len(where_conditions) == 1:\n",
    "            where_clause = where_conditions[0]\n",
    "    \n",
    "    # Perform the query with filters\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=k,\n",
    "        where=where_clause\n",
    "    )\n",
    "    \n",
    "    retrieved_ids = results['ids'][0]\n",
    "    \n",
    "    return retrieved_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to run the evaluation\n",
    "def run_evaluation(queries, expected_ids, collection, k_values=[3, 5, 10]):\n",
    "    \"\"\"Run evaluation for both retrieval methods across different k values\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for k in tqdm(k_values, desc=\"Evaluating k values\"):\n",
    "        pure_semantic_metrics = []\n",
    "        metadata_filtering_metrics = []\n",
    "        \n",
    "        for i, (query, expected) in enumerate(tqdm(zip(queries, expected_ids), desc=f\"Evaluating queries for k={k}\", total=len(queries))):\n",
    "            # Get the filters for this query\n",
    "            query_filters = filters[i] if i < len(filters) else None\n",
    "            \n",
    "            # Run pure semantic search\n",
    "            pure_semantic_results = pure_semantic_search(query, collection, k=k)\n",
    "            pure_semantic_eval = evaluate_retrieval(pure_semantic_results, expected)\n",
    "            pure_semantic_metrics.append(pure_semantic_eval)\n",
    "            \n",
    "            # Run semantic search with metadata filtering\n",
    "            metadata_results = semantic_search_with_metadata(query, collection, query_filters, k=k)\n",
    "            metadata_eval = evaluate_retrieval(metadata_results, expected)\n",
    "            metadata_filtering_metrics.append(metadata_eval)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_pure_recall = np.mean([m[\"recall\"] for m in pure_semantic_metrics])\n",
    "        avg_pure_mrr = np.mean([m[\"mrr\"] for m in pure_semantic_metrics])\n",
    "        \n",
    "        avg_metadata_recall = np.mean([m[\"recall\"] for m in metadata_filtering_metrics])\n",
    "        avg_metadata_mrr = np.mean([m[\"mrr\"] for m in metadata_filtering_metrics])\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": \"pure_semantic\",\n",
    "            \"avg_recall\": avg_pure_recall,\n",
    "            \"avg_mrr\": avg_pure_mrr\n",
    "        })\n",
    "        \n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"method\": \"metadata_filtering\",\n",
    "            \"avg_recall\": avg_metadata_recall,\n",
    "            \"avg_mrr\": avg_metadata_mrr\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries for k=3: 100%|██████████| 191/191 [03:52<00:00,  1.22s/it]\n",
      "Evaluating queries for k=5: 100%|██████████| 191/191 [04:06<00:00,  1.29s/it]\n",
      "Evaluating queries for k=10: 100%|██████████| 191/191 [03:32<00:00,  1.11s/it]\n",
      "Evaluating k values: 100%|██████████| 3/3 [11:31<00:00, 230.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the evaluation data\n",
    "queries = [item[\"query\"] for item in synthetic_queries]\n",
    "expected_ids = [[str(item[\"id\"])] for item in synthetic_queries]  # Each expected ID as a list\n",
    "\n",
    "# Run the evaluation\n",
    "k_values = [3, 5, 10]\n",
    "results_df = run_evaluation(queries, expected_ids, collection, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    k              method  avg_recall   avg_mrr\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>       pure_semantic    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.921466</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.846422</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  metadata_filtering    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.816754</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.779232</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>       pure_semantic    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.926702</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.847731</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  metadata_filtering    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.837696</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.784206</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>       pure_semantic    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.942408</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.849913</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>  metadata_filtering    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.858639</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.787354</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    k              method  avg_recall   avg_mrr\n",
       "\u001b[1;36m0\u001b[0m   \u001b[1;36m3\u001b[0m       pure_semantic    \u001b[1;36m0.921466\u001b[0m  \u001b[1;36m0.846422\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m   \u001b[1;36m3\u001b[0m  metadata_filtering    \u001b[1;36m0.816754\u001b[0m  \u001b[1;36m0.779232\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m   \u001b[1;36m5\u001b[0m       pure_semantic    \u001b[1;36m0.926702\u001b[0m  \u001b[1;36m0.847731\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m   \u001b[1;36m5\u001b[0m  metadata_filtering    \u001b[1;36m0.837696\u001b[0m  \u001b[1;36m0.784206\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m10\u001b[0m       pure_semantic    \u001b[1;36m0.942408\u001b[0m  \u001b[1;36m0.849913\u001b[0m\n",
       "\u001b[1;36m5\u001b[0m  \u001b[1;36m10\u001b[0m  metadata_filtering    \u001b[1;36m0.858639\u001b[0m  \u001b[1;36m0.787354\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Whilst writing this blogpost, I had secretly 'hoped' that hybrid search would outperform pure semantic search. Most people default to vector embeddings, but in production I found that structured metadata extraction consistently delivered better results. But this analysis shows that no application is the same. There is no 'universal' best method for doing things - it depends on the specific use case and the data at hand. I hope this analysis helps you make informed decisions about the best approach for your own use case. In the next cookbook, we'll be looking at evaluating tool calling! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
