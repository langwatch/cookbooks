{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Multi-Turn Conversations with Simulated Interactions\n",
    "\n",
    "In this notebook, we'll explore a more effective approach to evaluating multi-turn customer support agents. Traditional evaluation methods that use a single input-output pair are insufficient for agents that need to adapt their tool usage as conversations evolve. Instead, we'll implement a simulation-based approach where an LLM evaluates our agent against specific success criteria.\n",
    "\n",
    "## The Problem with Traditional Evaluation\n",
    "\n",
    "Traditional evaluation methods for customer support agents often use a dataset where:\n",
    "- Input: Customer ticket/query\n",
    "- Output: Expected sequence of tool calls\n",
    "\n",
    "This approach has significant limitations:\n",
    "1. It assumes a fixed, predetermined path to resolution\n",
    "2. It doesn't account for new information discovered during the conversation\n",
    "3. It focuses on the exact sequence of tools rather than achieving the desired outcome\n",
    "\n",
    "## A Better Approach: Simulation-Based Evaluation\n",
    "\n",
    "Instead of predicting exact tool sequences, we'll define success criteria that focus on what the agent must accomplish, regardless of the specific path taken. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_criteria = [\n",
    "    \"Agent MUST call get_status(order_id)\",\n",
    "    \"Agent MUST inform user cancellation is possible IFF package.status != 'shipped'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach:\n",
    "- Focuses on outcomes rather than specific steps\n",
    "- Allows for multiple valid solution paths\n",
    "- Better reflects real-world customer support scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Before we start, make sure you have OpenAI installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Let's implement this simulation-based evaluation approach using mock tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock tools for our customer support agent\n",
    "import asyncio\n",
    "import json\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from openai import AsyncOpenAI\n",
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Mock database of orders\n",
    "ORDERS_DB = {\n",
    "    \"ORD123\": {\"status\": \"processing\", \"customer_id\": \"CUST456\", \"items\": [\"Product A\", \"Product B\"]},\n",
    "    \"ORD456\": {\"status\": \"shipped\", \"customer_id\": \"CUST789\", \"items\": [\"Product C\"]},\n",
    "    \"ORD789\": {\"status\": \"delivered\", \"customer_id\": \"CUST456\", \"items\": [\"Product D\"]}\n",
    "}\n",
    "\n",
    "# Mock database of customers\n",
    "CUSTOMERS_DB = {\n",
    "    \"CUST456\": {\"email\": \"customer1@example.com\", \"name\": \"John Doe\"},\n",
    "    \"CUST789\": {\"email\": \"customer2@example.com\", \"name\": \"Jane Smith\"}\n",
    "}\n",
    "\n",
    "# Tool definitions\n",
    "async def find_customer_by_email(email: str) -> Dict[str, Any]:\n",
    "    \"\"\"Find a customer by their email address.\"\"\"\n",
    "    for customer_id, customer in CUSTOMERS_DB.items():\n",
    "        if customer[\"email\"] == email:\n",
    "            return {\"customer_id\": customer_id, **customer}\n",
    "    return {\"error\": \"Customer not found\"}\n",
    "\n",
    "async def get_orders_by_customer_id(customer_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get all orders for a specific customer.\"\"\"\n",
    "    orders = []\n",
    "    for order_id, order in ORDERS_DB.items():\n",
    "        if order[\"customer_id\"] == customer_id:\n",
    "            orders.append({\"order_id\": order_id, **order})\n",
    "    return {\"orders\": orders}\n",
    "\n",
    "async def get_order_status(order_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get the status of a specific order.\"\"\"\n",
    "    if order_id in ORDERS_DB:\n",
    "        return {\"order_id\": order_id, \"status\": ORDERS_DB[order_id][\"status\"]}\n",
    "    return {\"error\": \"Order not found\"}\n",
    "\n",
    "async def update_ticket_status(ticket_id: str, status: str) -> Dict[str, Any]:\n",
    "    \"\"\"Update the status of a support ticket.\"\"\"\n",
    "    return {\"ticket_id\": ticket_id, \"status\": status, \"updated\": True}\n",
    "\n",
    "async def escalate_to_human() -> Dict[str, Any]:\n",
    "    \"\"\"Escalate the current issue to a human agent.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"escalated\",\n",
    "        \"message\": \"A human agent has been notified and will follow up shortly.\"\n",
    "    }\n",
    "\n",
    "# Dictionary mapping tool names to functions\n",
    "TOOL_MAP = {\n",
    "    \"find_customer_by_email\": find_customer_by_email,\n",
    "    \"get_orders_by_customer_id\": get_orders_by_customer_id,\n",
    "    \"get_order_status\": get_order_status,\n",
    "    \"update_ticket_status\": update_ticket_status,\n",
    "    \"escalate_to_human\": escalate_to_human\n",
    "}\n",
    "\n",
    "# Tool schemas for OpenAI API\n",
    "TOOL_SCHEMAS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"find_customer_by_email\",\n",
    "            \"description\": \"Find a customer by their email address.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"email\": {\"type\": \"string\", \"description\": \"Customer email address\"}\n",
    "                },\n",
    "                \"required\": [\"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_orders_by_customer_id\",\n",
    "            \"description\": \"Get all orders for a specific customer.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"customer_id\": {\"type\": \"string\", \"description\": \"Customer ID\"}\n",
    "                },\n",
    "                \"required\": [\"customer_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_order_status\",\n",
    "            \"description\": \"Get the status of a specific order.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\"type\": \"string\", \"description\": \"Order ID\"}\n",
    "                },\n",
    "                \"required\": [\"order_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"update_ticket_status\",\n",
    "            \"description\": \"Update the status of a support ticket.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"ticket_id\": {\"type\": \"string\", \"description\": \"Ticket ID\"},\n",
    "                    \"status\": {\"type\": \"string\", \"description\": \"New status\"}\n",
    "                },\n",
    "                \"required\": [\"ticket_id\", \"status\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"escalate_to_human\",\n",
    "            \"description\": \"Escalate the current issue to a human agent.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "\n",
    "Now we define our agents. We will define both a Planner and an Executor agent. The Planner agent is responsible for creating a plan to achieve the user's goal, while the Executor agent is responsible for executing the plan. We also define a helper function to generate a response from the tool outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlannerAgent:\n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.client = AsyncOpenAI(api_key=api_key)\n",
    "        \n",
    "    async def run(self, task_history: List[Dict[str, Any]]) -> Tuple[List, str]:\n",
    "        \"\"\"Create a tool execution plan based on user input\"\"\"\n",
    "        # Call OpenAI to create a plan\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=task_history,\n",
    "            tools=TOOL_SCHEMAS,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        tool_calls = message.tool_calls or []\n",
    "        return tool_calls, message.content or \"\"\n",
    "\n",
    "    def initialize_history(self, ticket: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Start conversation history from a ticket.\"\"\"\n",
    "        system_prompt = \"\"\"You are a helpful customer support agent for an e-commerce company.\n",
    "        Your job is to help customers with their inquiries about orders, products, and returns.\n",
    "        Use the available tools to gather information and take actions on behalf of the customer.\n",
    "        Always be polite, professional, and helpful.\"\"\"\n",
    "        \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": str(ticket)}\n",
    "        ]\n",
    "\n",
    "# Simple implementation of the Executor Agent\n",
    "class ExecutorAgent:\n",
    "    async def run(self, tool_calls: List, task_history: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute tool calls and update conversation history\"\"\"\n",
    "        tool_outputs = []\n",
    "\n",
    "        for call in tool_calls:\n",
    "            tool_name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "\n",
    "            # Get the function from our tool map\n",
    "            func = TOOL_MAP.get(tool_name)\n",
    "            if func is None:\n",
    "                output = {\"error\": f\"Tool '{tool_name}' not found\"}\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Execute the tool\n",
    "                output = await func(**args)\n",
    "            except Exception as e:\n",
    "                output = {\"error\": str(e)}\n",
    "            \n",
    "            # Add the tool call to history\n",
    "            task_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": None,\n",
    "                \"tool_calls\": [{\n",
    "                    \"id\": call.id,\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_name,\n",
    "                        \"arguments\": call.function.arguments\n",
    "                    }\n",
    "                }]\n",
    "            })\n",
    "            \n",
    "            # Add the tool response to history\n",
    "            task_history.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"content\": json.dumps(output)\n",
    "            })\n",
    "\n",
    "            tool_outputs.append({\"tool_name\": tool_name, \"output\": output})\n",
    "\n",
    "        return {\"task_history\": task_history, \"tool_outputs\": tool_outputs}\n",
    "\n",
    "# Generate a response from tool outputs\n",
    "async def generate_response(tool_outputs: List[Dict], model: str = \"gpt-4o\") -> str:\n",
    "    \"\"\"Generate a human-readable response based on tool outputs\"\"\"\n",
    "    client = AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "    system_prompt = \"\"\"You are a helpful customer support agent. IMPORTANT GUIDELINES:\n",
    "    1. When a customer asks about cancellation, ALWAYS check the order status first\n",
    "    2. EXPLICITLY inform the customer if cancellation is possible based on the status:\n",
    "    - If status is 'processing' or 'pending', tell them cancellation IS possible\n",
    "    - If status is 'shipped' or 'delivered', tell them cancellation is NOT possible\n",
    "    3. Always be polite, professional, and helpful\"\"\"\n",
    "\n",
    "    # Prepare a prompt that includes the tool outputs\n",
    "    prompt = \"Based on the tool outputs, generate a helpful response to the customer:\\n\\n\"\n",
    "    for output in tool_outputs:\n",
    "        prompt += f\"{output['tool_name']} result: {json.dumps(output['output'])}\\n\"\n",
    "        \n",
    "    # Call OpenAI to generate the response\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "    # Prepare a prompt that includes the tool outputs\n",
    "    prompt = \"Based on the tool outputs, generate a helpful response to the customer:\\n\\n\"\n",
    "    for output in tool_outputs:\n",
    "        prompt += f\"{output['tool_name']} result: {json.dumps(output['output'])}\\n\"\n",
    "        \n",
    "    # Call OpenAI to generate the response\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful customer support agent. Generate a clear, concise response based on the tool outputs.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator Agent\n",
    "\n",
    "The Evaluator Agent evaluates our multi-turn agent behavior using binary success criteria over full simulated conversations. This method moves beyond traditional input/output (I/O) pair evaluation, addressing the stochastic and flexible nature of agent workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Verdict(BaseModel):\n",
    "    criterion: str\n",
    "    passed: bool\n",
    "    explanation: str\n",
    "\n",
    "class VerdictList(BaseModel):\n",
    "    verdicts: list[Verdict]\n",
    "\n",
    "async def evaluate_conversation(conversation: List[Dict], tools_used: List[str], criteria: List[str], model: str = \"gpt-4o\") -> Dict[str, Any]:\n",
    "    \"\"\"Evaluate a conversation against success criteria\"\"\"\n",
    "    client = AsyncOpenAI(api_key=api_key)\n",
    "    \n",
    "    # Format the conversation for evaluation\n",
    "    conversation_text = \"\"\n",
    "    for message in conversation:\n",
    "        role = message.get(\"role\", \"\")\n",
    "        content = message.get(\"content\", \"\")\n",
    "        if role == \"user\":\n",
    "            conversation_text += f\"Customer: {content}\\n\"\n",
    "        elif role == \"assistant\" and content:\n",
    "            conversation_text += f\"Agent: {content}\\n\"\n",
    "        elif role == \"tool\":\n",
    "            conversation_text += f\"Tool Output: {content}\\n\"\n",
    "    \n",
    "    # Create the evaluation prompt\n",
    "    prompt = f\"\"\"\n",
    "    Please evaluate this customer support conversation against the success criteria.\n",
    "    \n",
    "    Conversation:\n",
    "    {conversation_text}\n",
    "    \n",
    "    Tools used: {', '.join(tools_used)}\n",
    "    \n",
    "    Success Criteria:\n",
    "    {', '.join(f'- {criterion}' for criterion in criteria)}\n",
    "    \n",
    "    For each criterion, determine if it was met (PASS) or not met (FAIL).\n",
    "    Provide a brief explanation for each verdict.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call OpenAI to evaluate\n",
    "    response = await client.responses.parse(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an objective evaluator of customer support conversations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        text_format=VerdictList\n",
    "    )\n",
    "    \n",
    "    # Process the evaluation response\n",
    "    eval_text = response.output_parsed\n",
    "    \n",
    "    # Parse the evaluation into structured results\n",
    "    verdicts = eval_text.verdicts\n",
    "    \n",
    "    return {\"verdicts\": verdicts, \"raw_evaluation\": eval_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Function\n",
    "\n",
    "Below we define a method to simulate conversations between our agent and a user. The outputs will be evaluated by our Evaluator Agent in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simulate_conversation(ticket: Dict[str, Any], criteria: List[str], max_turns: int = 5):\n",
    "    \"\"\"Simulate a conversation with a customer and evaluate against criteria\"\"\"\n",
    "    # Initialize agents\n",
    "    planner = PlannerAgent()\n",
    "    executor = ExecutorAgent()\n",
    "    \n",
    "    # Initialize conversation history\n",
    "    task_history = planner.initialize_history(ticket)\n",
    "    \n",
    "    # Simulate the conversation\n",
    "    tools_used = []\n",
    "    turns = 0\n",
    "    \n",
    "    print(\"\\nü§ñ Starting conversation simulation...\")\n",
    "    print(f\"üìù Ticket: {ticket['subject']}\")\n",
    "    print(f\"üéØ Success criteria: {', '.join(criteria)}\")\n",
    "    \n",
    "    while turns < max_turns:\n",
    "        turns += 1\n",
    "        print(f\"\\n--- Turn {turns} ---\")\n",
    "        \n",
    "        # Run the planner to decide what to do\n",
    "        tool_calls, assistant_reply = await planner.run(task_history)\n",
    "        \n",
    "        # Handle the agent's response\n",
    "        if tool_calls:\n",
    "            # Agent wants to use tools\n",
    "            tool_names = [call.function.name for call in tool_calls]\n",
    "            print(f\"üîß Agent uses tools: {', '.join(tool_names)}\")\n",
    "            tools_used.extend(tool_names)\n",
    "            \n",
    "            # Execute the tools\n",
    "            result = await executor.run(tool_calls, task_history)\n",
    "            \n",
    "            # Generate a response based on tool outputs\n",
    "            response_text = await generate_response(result[\"tool_outputs\"])\n",
    "            print(f\"ü§ñ Agent: {response_text}\")\n",
    "            \n",
    "            # Add the response to history\n",
    "            task_history.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "            \n",
    "            # Check if conversation should end\n",
    "            if \"update_ticket_status\" in tool_names:\n",
    "                print(\"\\n‚úÖ Ticket resolved ‚Äî update_ticket_status was called.\")\n",
    "                break\n",
    "        else:\n",
    "            # Agent responded directly without tools\n",
    "            print(f\"ü§ñ Agent: {assistant_reply}\")\n",
    "            task_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "        \n",
    "        # Get simulated user input\n",
    "        if turns <= max_turns:\n",
    "            user_input = input(\"User: \")\n",
    "            print(f\"üë§ Customer: {user_input}\")\n",
    "            task_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        else:\n",
    "            # If we run out of predefined responses, end the conversation\n",
    "            break\n",
    "    \n",
    "    # Evaluate the conversation\n",
    "    print(\"\\nüìä Evaluating conversation...\")\n",
    "    evaluation = await evaluate_conversation(task_history, tools_used, criteria)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    for verdict in evaluation[\"verdicts\"]:\n",
    "        status = \"‚úÖ PASS\" if verdict.passed else \"‚ùå FAIL\"\n",
    "        print(f\"{status}: {verdict.criterion}\")\n",
    "    \n",
    "    # Calculate overall score\n",
    "    passed = sum(1 for v in evaluation[\"verdicts\"] if v.passed)\n",
    "    total = len(evaluation[\"verdicts\"])\n",
    "    score = (passed / total) * 100\n",
    "    \n",
    "    print(f\"\\nüìà Overall Score: {score:.1f}% ({passed}/{total} criteria met)\")\n",
    "    print(f\"üîß Tools Used: {', '.join(set(tools_used))}\")\n",
    "    print(f\"üîÑ Conversation Length: {turns} turns\")\n",
    "    \n",
    "    return {\n",
    "        \"conversation\": task_history,\n",
    "        \"tools_used\": tools_used,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"turns\": turns,\n",
    "        \"score\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a ticket and our success criteria. Then we're ready to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Starting conversation simulation...\n",
      "üìù Ticket: Order Cancellation Request\n",
      "üéØ Success criteria: Agent MUST call get_order_status tool, Agent MUST inform user cancellation is possible IFF order.status != 'shipped'\n",
      "\n",
      "--- Turn 1 ---\n",
      "üîß Agent uses tools: find_customer_by_email\n",
      "ü§ñ Agent: Hello John Doe,\n",
      "\n",
      "Thank you for reaching out to us! How can I assist you today? If you have any concerns or questions regarding your order, please provide me with your order number, and I'll be happy to help you further.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "üë§ Customer: ehm my order id is 123\n",
      "\n",
      "--- Turn 2 ---\n",
      "üîß Agent uses tools: get_order_status\n",
      "ü§ñ Agent: Thank you for reaching out regarding your order ORD123. I checked the status, and it is currently marked as \"processing.\" I'm happy to inform you that cancellation is possible at this stage. If you would like to proceed with canceling your order, please let me know, and I will assist you further. If there's anything else I can do for you, feel free to ask.\n",
      "üë§ Customer: yeah go ahead mate\n",
      "\n",
      "--- Turn 3 ---\n",
      "üîß Agent uses tools: update_ticket_status\n",
      "ü§ñ Agent: Hello,\n",
      "\n",
      "Thank you for reaching out to us. I'm writing to inform you that the status of your ticket (ID: TICKET123) has been successfully updated to \"closed.\" If there's anything else we can assist you with, or if you need further clarification, please don't hesitate to contact us.\n",
      "\n",
      "We appreciate your patience and understanding. Have a great day!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team\n",
      "\n",
      "‚úÖ Ticket resolved ‚Äî update_ticket_status was called.\n",
      "\n",
      "üìä Evaluating conversation...\n",
      "\n",
      "--- Evaluation Results ---\n",
      "‚úÖ PASS: Agent MUST call get_order_status tool\n",
      "‚úÖ PASS: Agent MUST inform user cancellation is possible IFF order.status != 'shipped'\n",
      "\n",
      "üìà Overall Score: 100.0% (2/2 criteria met)\n",
      "üîß Tools Used: find_customer_by_email, update_ticket_status, get_order_status\n",
      "üîÑ Conversation Length: 3 turns\n"
     ]
    }
   ],
   "source": [
    "async def run_example():\n",
    "    # Define a test ticket\n",
    "    ticket = {\n",
    "        \"id\": \"TICKET123\",\n",
    "        \"subject\": \"Order Cancellation Request\",\n",
    "        \"description\": \"I placed an order yesterday (ORD123) and would like to cancel it if it hasn't shipped yet.\",\n",
    "        \"status\": \"open\",\n",
    "        \"requester_id\": \"customer1@example.com\"\n",
    "    }\n",
    "    \n",
    "    # Define success criteria\n",
    "    criteria = [\n",
    "        \"Agent MUST call get_order_status tool\",\n",
    "        \"Agent MUST inform user cancellation is possible IFF order.status != 'shipped'\"\n",
    "    ]\n",
    "    \n",
    "    # Run the simulation\n",
    "    await simulate_conversation(ticket, criteria)\n",
    "\n",
    "await run_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Traditional evaluation methods that rely on fixed input-output pairs are insufficient for multi-turn conversational agents. By simulating complete conversations and evaluating against outcome-based criteria, we can better assess an agent's ability to handle real-world customer support scenarios.\n",
    "\n",
    "This approach allows us to focus on what matters‚Äîsuccessfully resolving customer issues‚Äîrather than following a predetermined sequence of steps. As your agent evolves, you can refine your success criteria to ensure it meets your business needs while providing excellent customer service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
