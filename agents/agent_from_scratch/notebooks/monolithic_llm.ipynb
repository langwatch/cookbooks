{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Eval Set & Baseline Implementation\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook introduces:\n",
    "- A synthetic evaluation set for customer support queries\n",
    "- A baseline monolithic LLM system (no tools)\n",
    "- Evaluation logic to track how well it answers queries based on policy\n",
    "\n",
    "We'll use a simulated product catalog, return policy, and order data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "First, let's install the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import openai\n",
    "import getpass\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = getpass.getpass('Enter your OpenAI API key: ')\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Synthetic Data\n",
    "\n",
    "Before we start building, we need to curate a dataset. This is necessary to ensure that our agent is making the right choices. Since we don't have production data, we can synthetically generate some. I'll go ahead and generate 20 customer support queries related to refunds. This is enough to get started. I can't stress this enough, but evaluating your AI agents is not a one-time thing. It's a continuous process that should be done after each iteration of your development cycle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_info</th>\n",
       "      <th>expected_tool_sequence</th>\n",
       "      <th>expected_response_contains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I return my Leather Wallet?</td>\n",
       "      <td>C001</td>\n",
       "      <td>[{'product_name': 'Leather Wallet', 'order_id'...</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[eligible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I return my Wireless Headphones?</td>\n",
       "      <td>C002</td>\n",
       "      <td>[{'product_name': 'Wireless Headphones', 'orde...</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[not eligible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I return my Yoga Mat?</td>\n",
       "      <td>C003</td>\n",
       "      <td>[{'product_name': 'Yoga Mat', 'order_id': 'ORD...</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[eligible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I return my Wireless Headphones?</td>\n",
       "      <td>C004</td>\n",
       "      <td>[{'product_name': 'Wireless Headphones', 'orde...</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[not eligible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I return my Leather Wallet?</td>\n",
       "      <td>C005</td>\n",
       "      <td>[{'product_name': 'Leather Wallet', 'order_id'...</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[eligible]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  query customer_id  \\\n",
       "0       Can I return my Leather Wallet?        C001   \n",
       "1  Can I return my Wireless Headphones?        C002   \n",
       "2             Can I return my Yoga Mat?        C003   \n",
       "3  Can I return my Wireless Headphones?        C004   \n",
       "4       Can I return my Leather Wallet?        C005   \n",
       "\n",
       "                                          order_info expected_tool_sequence  \\\n",
       "0  [{'product_name': 'Leather Wallet', 'order_id'...                 [none]   \n",
       "1  [{'product_name': 'Wireless Headphones', 'orde...                 [none]   \n",
       "2  [{'product_name': 'Yoga Mat', 'order_id': 'ORD...                 [none]   \n",
       "3  [{'product_name': 'Wireless Headphones', 'orde...                 [none]   \n",
       "4  [{'product_name': 'Leather Wallet', 'order_id'...                 [none]   \n",
       "\n",
       "  expected_response_contains  \n",
       "0                 [eligible]  \n",
       "1             [not eligible]  \n",
       "2                 [eligible]  \n",
       "3             [not eligible]  \n",
       "4                 [eligible]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = [\n",
    "    {\"product_name\": \"Wireless Headphones\", \"category\": \"Electronics\"},\n",
    "    {\"product_name\": \"Running Shoes\", \"category\": \"Footwear\"},\n",
    "    {\"product_name\": \"Leather Wallet\", \"category\": \"Accessories\"},\n",
    "    {\"product_name\": \"Smartwatch\", \"category\": \"Electronics\"},\n",
    "    {\"product_name\": \"Yoga Mat\", \"category\": \"Fitness\"}\n",
    "]\n",
    "\n",
    "return_policy_days = {\n",
    "    \"Electronics\": 14,\n",
    "    \"Footwear\": 30,\n",
    "    \"Accessories\": 30,\n",
    "    \"Fitness\": 20\n",
    "}\n",
    "\n",
    "today = datetime.strptime(\"2025-04-23\", \"%Y-%m-%d\")\n",
    "examples = []\n",
    "\n",
    "for i in range(20):\n",
    "    product = random.choice(products)\n",
    "    order_date = today - timedelta(days=random.randint(5, 45))\n",
    "    policy_days = return_policy_days[product[\"category\"]]\n",
    "    refund_eligible = (today - order_date).days <= policy_days\n",
    "\n",
    "    examples.append({\n",
    "        \"query\": f\"Can I return my {product['product_name']}?\",\n",
    "        \"customer_id\": f\"C{i+1:03}\",\n",
    "        \"order_info\": [{\n",
    "            \"product_name\": product[\"product_name\"],\n",
    "            \"order_id\": f\"ORD{i+1000}\",\n",
    "            \"order_date\": order_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"amount\": round(random.uniform(20, 200), 2),\n",
    "            \"return_policy_days\": policy_days\n",
    "        }],\n",
    "        \"expected_tool_sequence\": [\"none\"],\n",
    "        \"expected_response_contains\": [\n",
    "            \"not eligible\" if not refund_eligible else \"eligible\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "df_eval = pd.DataFrame(examples)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the expected_tool_sequence fields are empty for now. We'll fill them in later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the LLM\n",
    "\n",
    "We'll use OpenAI's GPT-4o for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_monolithic_llm(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Call a monolithic LLM using just the query.\n",
    "    Replace with your actual OpenAI or local model call.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Respond with eligible or not eligible based on the following query: {query}\\n\\n Do not say anything else.\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "def run_monolithic_llm_responses(df):\n",
    "    responses = []\n",
    "    for _, row in df.iterrows():\n",
    "        response = call_monolithic_llm(row[\"query\"])\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "df_eval[\"baseline_response\"] = run_monolithic_llm_responses(df_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Let's evaluate the monolithic LLM responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (exact match on all expected phrases): 60.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(row):\n",
    "    response = row[\"baseline_response\"].lower()\n",
    "    score = sum(1 for phrase in row[\"expected_response_contains\"] if phrase.lower() in response)\n",
    "    return score / len(row[\"expected_response_contains\"])\n",
    "\n",
    "df_eval[\"baseline_score\"] = df_eval.apply(evaluate_response, axis=1)\n",
    "df_eval[[\"query\", \"baseline_response\", \"baseline_score\"]].head()\n",
    "\n",
    "# Summary Stats\n",
    "accuracy = (df_eval[\"baseline_score\"] == 1.0).mean()\n",
    "print(f\"Baseline Accuracy (exact match on all expected phrases): {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously completely random, since the LLM did not have access to our customer data. Let's improve the reliability of the LLM by giving it access to its first tool, a retriever. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
